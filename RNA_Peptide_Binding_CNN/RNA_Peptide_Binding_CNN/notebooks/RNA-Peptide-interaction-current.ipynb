{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "70a448e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "from tqdm import tqdm\n",
    "from itertools import islice\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import glob\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from Bio import SeqIO\n",
    "from Bio.PDB import PDBList, PDBParser, PPBuilder\n",
    "from Bio.Seq import Seq\n",
    "from Bio.PDB.Polypeptide import is_aa\n",
    "from Bio.SeqUtils import seq1\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cbac2213",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_single_fasta_file(path):\n",
    "    with open(path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    sequence = ''.join([line.strip() for line in lines if not line.startswith(\">\")])\n",
    "    return sequence\n",
    "\n",
    "def parse_fasta_file(filepath):\n",
    "    try:\n",
    "        return [str(record.seq) for record in SeqIO.parse(filepath, \"fasta\")]\n",
    "    except Exception:\n",
    "        return []  # Skip malformed files\n",
    "\n",
    "# Function to gather all .fasta/.fa files recursively\n",
    "def get_fasta_files_from_nested_folders(root_folder, limit=None):\n",
    "    files = glob.glob(os.path.join(root_folder, \"**\", \"*.fa*\"), recursive=True)\n",
    "    return list(islice(files, limit)) if limit else list(files)\n",
    "\n",
    "# Function to load sequences from multiple files using multiprocessing\n",
    "def load_fasta_sequences_parallel(file_list, num_workers=4):\n",
    "    with ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "        results = executor.map(parse_fasta_file, file_list)\n",
    "        return list(chain.from_iterable(results))\n",
    "\n",
    "def parse_fasta_sequences(filepath):\n",
    "    peptides = []\n",
    "    with open(filepath, 'r') as f:\n",
    "        current_seq = ''\n",
    "        for line in f:\n",
    "            if line.startswith('>'):\n",
    "                if current_seq:\n",
    "                    peptides.append(current_seq)\n",
    "                    current_seq = ''\n",
    "            else:\n",
    "                current_seq += line.strip()\n",
    "        if current_seq:\n",
    "            peptides.append(current_seq)\n",
    "    return peptides\n",
    "\n",
    "fasta_files = get_fasta_files_from_nested_folders(\"RNA_FASTA_Files\", limit=200000)\n",
    "rna_seqs = load_fasta_sequences_parallel(fasta_files, num_workers=8)\n",
    "peptide_seqs = parse_fasta_sequences(\"peptideatlas.fasta\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f9dfa7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_multiple_pdbs(pair_file, out_dir):\n",
    "    from Bio.PDB import PDBList\n",
    "    import os\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    pdbl = PDBList()\n",
    "    pdb_ids = set()\n",
    "\n",
    "    with open(pair_file, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) != 2 or parts[0].lower() == \"protein\":\n",
    "                continue  # Skip headers or malformed lines\n",
    "            prot, rna = parts\n",
    "            pdb_ids.add(prot.split(\"_\")[0].lower())\n",
    "\n",
    "    for pdb_id in sorted(pdb_ids):\n",
    "        try:\n",
    "            url = f\"https://files.rcsb.org/download/{pdb_id.upper()}.pdb\"\n",
    "            filepath = os.path.join(out_dir, f\"{pdb_id}.pdb\")\n",
    "            if not os.path.exists(filepath):\n",
    "                import urllib.request\n",
    "                urllib.request.urlretrieve(url, filepath)\n",
    "        except Exception as e:\n",
    "          print(f'Nothing')\n",
    "\n",
    "        \n",
    "#download_multiple_pdbs(\"RPI2241.txt\", \"./pdb_files\")\n",
    "\n",
    "def load_rpi2241_pairs(filepath):\n",
    "    pairs = set()\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) != 2 or parts[0].lower() == \"protein\":\n",
    "                continue  # Skip headers or malformed lines\n",
    "            prot, rna = parts\n",
    "            pairs.add((prot.upper(), rna.upper()))\n",
    "    return pairs\n",
    "\n",
    "rpi2241_positive_pairs=load_rpi2241_pairs(\"RPI2241.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0d8f28a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding function for RNA and Peptide sequences\n",
    "def one_hot_encodeRNA(sequence):\n",
    "    mapping = {'A': 0, 'U': 1, 'G': 2, 'C': 3}\n",
    "    one_hot = np.zeros((len(sequence), 4))\n",
    "    for i, base in enumerate(sequence):\n",
    "        if base in mapping:\n",
    "            one_hot[i, mapping[base]] = 1\n",
    "    return torch.tensor(one_hot, dtype=torch.float)\n",
    "def one_hot_encodepeptide(sequence):\n",
    "    amino_acids = ['A', 'R', 'N', 'D', 'C', 'E', 'Q', 'G', 'H', 'I',\n",
    "    'L', 'K', 'M', 'F', 'P', 'S', 'T', 'W', 'Y', 'V']\n",
    "    aa_to_index = {aa: idx for idx, aa in enumerate(amino_acids)}\n",
    "    one_hot = np.zeros((len(sequence), 20))\n",
    "    for i, aa in enumerate(sequence):\n",
    "        if aa in aa_to_index:\n",
    "            one_hot[i, aa_to_index[aa]] = 1\n",
    "    return torch.tensor(one_hot, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "121a0928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_protein_sequence(pdb_file, chain_id):\n",
    "    parser = PDBParser(QUIET=True)\n",
    "    structure = parser.get_structure(\"protein\", pdb_file)\n",
    "    for model in structure:\n",
    "        if chain_id in model:\n",
    "            chain = model[chain_id]\n",
    "            peptides = PPBuilder().build_peptides(chain)\n",
    "            if peptides:\n",
    "                return str(peptides[0].get_sequence())\n",
    "    return None\n",
    "\n",
    "RNA_MAP = {\n",
    "    \"ADE\": \"A\", \"CYT\": \"C\", \"GUA\": \"G\", \"URI\": \"U\",\n",
    "    \"PSU\": \"U\", \"INO\": \"I\", \"GTP\": \"G\", \"OMC\": \"C\",\n",
    "    \"A\": \"A\", \"C\": \"C\", \"G\": \"G\", \"U\": \"U\"  # Handle both 1/3-letter\n",
    "}\n",
    "\n",
    "def extract_rna_sequence(pdb_file, chain_id):\n",
    "    parser = PDBParser(QUIET=True)\n",
    "    structure = parser.get_structure(\"rna\", pdb_file)\n",
    "    sequence = \"\"\n",
    "    \n",
    "    # Use first model only\n",
    "    model = structure[0]\n",
    "    if chain_id not in model:\n",
    "        return None\n",
    "    \n",
    "    for residue in model[chain_id]:\n",
    "        # Skip heteroatoms and insertions\n",
    "        residue_id = residue.get_id()\n",
    "        if residue_id[0] != \" \":\n",
    "            continue\n",
    "            \n",
    "        resname = residue.get_resname().strip().upper()\n",
    "        if resname in RNA_MAP:\n",
    "            sequence += RNA_MAP[resname]\n",
    "    \n",
    "    return sequence if sequence else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f63aad3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_structure_chains(pdb_files, pdb_dir):\n",
    "    structure_chains = defaultdict(lambda: {'protein': [], 'rna': []})\n",
    "    parser = PDBParser(QUIET=True)\n",
    "    \n",
    "    for pdb_file in pdb_files:\n",
    "        pdb_id = os.path.splitext(os.path.basename(pdb_file))[0].lower()\n",
    "        pdb_path = os.path.join(pdb_dir, pdb_file)\n",
    "        try:\n",
    "            structure = parser.get_structure(pdb_id, pdb_path)\n",
    "            model = next(structure.get_models())\n",
    "            for chain in model.get_chains():\n",
    "                chain_id = chain.id.upper()\n",
    "                residues = list(chain.get_residues())\n",
    "                # Count amino acid residues\n",
    "                aa_residues = {\"ALA\", \"ARG\", \"ASN\", \"ASP\", \"CYS\", \"GLN\", \"GLU\", \"GLY\",\n",
    "                               \"HIS\", \"ILE\", \"LEU\", \"LYS\", \"MET\", \"PHE\", \"PRO\", \"SER\",\n",
    "                               \"THR\", \"TRP\", \"TYR\", \"VAL\"}\n",
    "                rna_residues = {\"ADE\", \"CYT\", \"GUA\", \"URI\", \"PSU\", \"INO\"}\n",
    "                \n",
    "                aa_count = sum(1 for r in residues if r.get_id()[0] == ' ' and r.get_resname() in aa_residues)\n",
    "                rna_count = sum(1 for r in residues if r.get_id()[0] == ' ' and r.get_resname() in rna_residues)\n",
    "                \n",
    "                if aa_count > rna_count:\n",
    "                    structure_chains[pdb_id]['protein'].append(f\"{pdb_id}_{chain_id}\")\n",
    "                elif rna_count > 0:\n",
    "                    structure_chains[pdb_id]['rna'].append(f\"{pdb_id}_{chain_id}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {pdb_file}: {e}\")\n",
    "    \n",
    "    return structure_chains\n",
    "    \n",
    "pdb_files = [f for f in os.listdir(\"./pdb_files\") if f.endswith(\".pdb\")]\n",
    "rpi_structure_chains = define_structure_chains(pdb_files,\"./pdb_files\")\n",
    "    \n",
    "def generate_structure_based_negatives(positive_pairs, structure_chains, num_negatives=None, seed=42):\n",
    "    random.seed(seed)\n",
    "    negative_pairs = set()\n",
    "\n",
    "    for pdb_id, chains in structure_chains.items():\n",
    "        protein_chains = chains.get(\"protein\", [])\n",
    "        rna_chains = chains.get(\"rna\", [])\n",
    "        for prot in protein_chains:\n",
    "            for rna in rna_chains:\n",
    "                if (prot, rna) not in positive_pairs:\n",
    "                    negative_pairs.add((prot, rna))\n",
    "                    \n",
    "    return negative_pairs\n",
    "\n",
    "rpi2241_negative_pairs = generate_structure_based_negatives(positive_pairs=rpi2241_positive_pairs, structure_chains=rpi_structure_chains, num_negatives=len(rpi2241_positive_pairs))\n",
    "\n",
    "# Attach labels\n",
    "positive_labeled = [(p, r, 1.0) for p, r in rpi2241_positive_pairs]\n",
    "negative_labeled = [(p, r, 0.0) for p, r in rpi2241_negative_pairs]\n",
    "\n",
    "# Combine and shuffle\n",
    "all_labeled_pairs = positive_labeled + negative_labeled\n",
    "random.shuffle(all_labeled_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3a325096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chain_sequence(chain):\n",
    "    sequence = \"\"\n",
    "    for residue in chain:\n",
    "        if residue.get_id()[0] != \" \":  # Skip heteroatoms/water\n",
    "            continue\n",
    "        resname = residue.get_resname()\n",
    "        try:\n",
    "            letter = seq1(resname)  # Convert 3-letter to 1-letter\n",
    "            sequence += letter\n",
    "        except Exception:\n",
    "            continue  # Skip unknown residues\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5ae9f56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing 2qnh: 'L'\n",
      "Error processing 2zkq: 'N'\n",
      "Error processing 3kix: 'Y'\n",
      "Error processing 3kis: 'Q'\n",
      "Error processing 2zkq: 'M'\n",
      "Error processing 2zkq: 'L'\n",
      "Error processing 2qnh: 'S'\n",
      "Error processing 3kis: 'H'\n",
      "Error processing 3kiu: 'O'\n",
      "Error processing 3kis: 'C'\n",
      "Error processing 2zkq: 'J'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\Bio\\File.py\u001b[0m in \u001b[0;36mas_handle\u001b[1;34m(handleish, mode, **kwargs)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandleish\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\Bio\\PDB\\PDBParser.py\u001b[0m in \u001b[0;36mget_structure\u001b[1;34m(self, id, file)\u001b[0m\n\u001b[0;32m     99\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Empty file.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\Bio\\PDB\\PDBParser.py\u001b[0m in \u001b[0;36m_parse\u001b[1;34m(self, header_coords_trailer)\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[1;31m# Parse the atomic data; return the PDB file trailer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrailer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_coordinates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoords_trailer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\Bio\\PDB\\PDBParser.py\u001b[0m in \u001b[0;36m_parse_coordinates\u001b[1;34m(self, coords_trailer)\u001b[0m\n\u001b[0;32m    298\u001b[0m                     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m                         structure_builder.init_atom(\n\u001b[0m\u001b[0;32m    300\u001b[0m                             \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\Bio\\PDB\\StructureBuilder.py\u001b[0m in \u001b[0;36minit_atom\u001b[1;34m(self, name, coord, b_factor, occupancy, altloc, fullname, serial_number, element, pqr_charge, radius, is_pqr)\u001b[0m\n\u001b[0;32m    230\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_pqr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m             self.atom = Atom(\n\u001b[0m\u001b[0;32m    232\u001b[0m                 \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\Bio\\PDB\\Atom.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, coord, bfactor, occupancy, altloc, fullname, serial_number, element, pqr_charge, radius)\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0melement\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0melement\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0melement\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melement\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0melement\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_assign_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_assign_atom_mass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\Bio\\PDB\\Atom.py\u001b[0m in \u001b[0;36m_assign_element\u001b[1;34m(self, element)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0m_assign_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m         \u001b[1;34m\"\"\"Guess element from atom name if not recognised (PRIVATE).\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-84-b967109a74dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mrna_padded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpep_padded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m \u001b[0mfull_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRNAPeptideDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabeled_pairs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mall_labeled_pairs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpdb_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"./pdb_files\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m \u001b[0mtrain_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.8\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[0mval_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.15\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-84-b967109a74dc>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, labeled_pairs, pdb_dir)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprecomputed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpairs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprecomputed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-84-b967109a74dc>\u001b[0m in \u001b[0;36m_load_item\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpdb_id\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstructure_cache\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m                 \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPDBParser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mQUIET\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m                 \u001b[0mstructure\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpdb_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpdb_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstructure_cache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpdb_id\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\Bio\\PDB\\PDBParser.py\u001b[0m in \u001b[0;36mget_structure\u001b[1;34m(self, id, file)\u001b[0m\n\u001b[0;32m     98\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Empty file.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstructure_builder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_header\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m    129\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m                 \u001b[1;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\Bio\\File.py\u001b[0m in \u001b[0;36mas_handle\u001b[1;34m(handleish, mode, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandleish\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[1;32myield\u001b[0m \u001b[0mhandleish\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class RNAPeptideDataset(Dataset):\n",
    "    def __init__(self, labeled_pairs, pdb_dir):\n",
    "        self.pairs = labeled_pairs\n",
    "        self.pdb_dir = pdb_dir\n",
    "        # Cache to store parsed structures\n",
    "        self.structure_cache = {}\n",
    "        # Cache to store extracted sequences\n",
    "        self.sequence_cache = {}\n",
    "        self.precomputed = []\n",
    "        for idx in range(len(self.pairs)):\n",
    "            self.precomputed.append(self._load_item(idx))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "    \n",
    "    def _load_item(self, idx):\n",
    "        prot_chain, rna_chain, label = self.pairs[idx]\n",
    "        pdb_id = prot_chain.split(\"_\")[0].lower()\n",
    "        pep_chain_id = prot_chain.split(\"_\")[1].upper()\n",
    "        rna_chain_id = rna_chain.split(\"_\")[1].upper()\n",
    "        \n",
    "        # Get PDB structure (with caching)\n",
    "        pdb_path = os.path.join(self.pdb_dir, f\"{pdb_id}.pdb\")\n",
    "        if not os.path.exists(pdb_path):\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            # Use cached structure if available\n",
    "            if pdb_id not in self.structure_cache:\n",
    "                parser = PDBParser(QUIET=True)\n",
    "                structure = parser.get_structure(pdb_id, pdb_path)\n",
    "                self.structure_cache[pdb_id] = structure\n",
    "            \n",
    "            structure = self.structure_cache[pdb_id]\n",
    "            model = next(structure.get_models())\n",
    "            \n",
    "            # Get chains (with caching)\n",
    "            cache_key = f\"{pdb_id}_{pep_chain_id}_{rna_chain_id}\"\n",
    "            if cache_key not in self.sequence_cache:\n",
    "                pep_chain = model[pep_chain_id]\n",
    "                rna_chain = model[rna_chain_id]\n",
    "                \n",
    "                pep_seq = get_chain_sequence(pep_chain)\n",
    "                rna_seq = get_chain_sequence(rna_chain)\n",
    "                \n",
    "                self.sequence_cache[cache_key] = (pep_seq, rna_seq)\n",
    "            else:\n",
    "                pep_seq, rna_seq = self.sequence_cache[cache_key]\n",
    "            \n",
    "            if not pep_seq or not rna_seq:\n",
    "                return None\n",
    "                \n",
    "            # Convert to tensors\n",
    "            rna_tensor = one_hot_encodeRNA(rna_seq).float()\n",
    "            pep_tensor = one_hot_encodepeptide(pep_seq).float()\n",
    "            label_tensor = torch.tensor(label, dtype=torch.float).view(1)\n",
    "            \n",
    "            return rna_tensor, pep_tensor, label_tensor\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {pdb_id}: {str(e)}\")\n",
    "            return None\n",
    "        \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.precomputed[idx]\n",
    "    \n",
    "def collate_fn(batch):\n",
    "    batch = [item for item in batch if item is not None]\n",
    "    if not batch: \n",
    "        return None\n",
    "    \n",
    "    rna_seqs, pep_seqs, labels = zip(*batch)\n",
    "    \n",
    "    # Pad RNA sequences (now [seq_len, 4])\n",
    "    rna_padded = pad_sequence(rna_seqs, batch_first=True)  # [batch, max_len, 4]\n",
    "    \n",
    "    # Pad peptide sequences (now [seq_len, 20])\n",
    "    pep_padded = pad_sequence(pep_seqs, batch_first=True)  # [batch, max_len, 20]\n",
    "    \n",
    "    labels = torch.stack(labels)\n",
    "    return rna_padded, pep_padded, labels\n",
    "\n",
    "full_dataset = RNAPeptideDataset(labeled_pairs=all_labeled_pairs, pdb_dir=\"./pdb_files\")\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = int(0.15 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(full_dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6f3c22fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CNN model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.rna_conv1 = nn.Conv1d(4, 16, kernel_size=3, padding=1)\n",
    "        self.rna_conv2 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
    "        self.rna_conv3 = nn.Conv1d(32, 64, kernel_size=3, padding=1)\n",
    "        self.rna_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.pep_conv1 = nn.Conv1d(20, 16, kernel_size=3, padding=1)\n",
    "        self.pep_conv2 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pep_conv3 = nn.Conv1d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pep_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc1 = nn.Linear(128, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        \n",
    "    def forward(self, rna_input, pep_input):\n",
    "        rna = F.relu(self.rna_conv1(rna_input.permute(0, 2, 1)))\n",
    "        rna = F.relu(self.rna_conv2(rna))\n",
    "        rna = F.relu(self.rna_conv3(rna))\n",
    "        rna = self.rna_pool(rna).squeeze(2)\n",
    "        \n",
    "        pep = F.relu(self.pep_conv1(pep_input.permute(0, 2, 1)))\n",
    "        pep = F.relu(self.pep_conv2(pep))\n",
    "        pep = F.relu(self.pep_conv3(pep))\n",
    "        pep = self.pep_pool(pep).squeeze(2)\n",
    "        \n",
    "        combined = torch.cat((rna, pep), dim=1)\n",
    "        x = F.relu(self.fc1(combined))\n",
    "        out = self.fc2(x)  \n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9be6349e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, loss, optimizer\n",
    "model = CNN()\n",
    "pos_weight = len(negative_labeled) / len(positive_labeled)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([pos_weight]))\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a2066a85",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (1533) must match the size of tensor b (2807) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-5709bd8f407f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mtrain_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Enhanced check\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    631\u001b[0m                 \u001b[1;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 633\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 677\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    678\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-71-cf2804cf8c5d>\u001b[0m in \u001b[0;36mcollate_fn\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[1;31m# Pad sequences\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m     \u001b[0mrna_padded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpad_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrna_seqs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m     \u001b[0mpep_padded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpad_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpep_seqs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\utils\\rnn.py\u001b[0m in \u001b[0;36mpad_sequence\u001b[1;34m(sequences, batch_first, padding_value)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[1;31m# assuming trailing dimensions and type of all the Tensors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[1;31m# in sequences are same and fetching those from sequences[0]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 399\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (1533) must match the size of tensor b (2807) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "# Move model to device (GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "for epoch in range(30):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "\n",
    "    for batch in train_loader:\n",
    "        if batch is None or len(batch[0]) == 0:  # Enhanced check\n",
    "            continue\n",
    "        \n",
    "        rna_batch, pep_batch, label_batch = batch\n",
    "        rna_batch = rna_batch.to(device)\n",
    "        pep_batch = pep_batch.to(device)\n",
    "        label_batch = label_batch.float().view(-1,1).to(device)\n",
    "        \n",
    "        scores = model(rna_batch, pep_batch)\n",
    "        loss = criterion(scores, label_batch)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0 and len(train_losses) > 0:\n",
    "        avg_loss = sum(train_losses) / len(train_losses)\n",
    "        print(f\"Epoch [{epoch + 1}/30], Loss: {avg_loss:.4f}\")\n",
    "        \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:  \n",
    "            if batch is None or len(batch[0]) == 0:  # Enhanced check\n",
    "                continue\n",
    "                \n",
    "            rna_batch, pep_batch, label_batch = batch\n",
    "            rna_batch = rna_batch.to(device)\n",
    "            pep_batch = pep_batch.to(device)\n",
    "            label_batch = label_batch.float().view(-1,1).to(device)\n",
    "            \n",
    "            rna_batch = rna_batch.permute(0, 2, 1)  \n",
    "            pep_batch = pep_batch.permute(0, 2, 1) \n",
    "            \n",
    "            val_scores = model(rna_batch, pep_batch)\n",
    "            val_loss = criterion(val_scores, label_batch)\n",
    "            val_losses.append(val_loss.item())\n",
    "            \n",
    "    if (epoch + 1) % 10 == 0 and len(val_losses) > 0:      \n",
    "        avg_val_loss = sum(val_losses) / len(val_losses)\n",
    "        print(f\"Epoch [{epoch + 1}/30], Val Loss: {avg_val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2256f73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"models/cnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16caa0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
