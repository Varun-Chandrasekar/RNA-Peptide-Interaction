#Execution code to gather RNA and peptide sequences.

fasta_files = get_fasta_files_from_nested_folders("/content/drive/MyDrive/Deep Learning/RNA-fastaFiles", limit=200000)
rna_seqs = load_fasta_sequences_parallel(fasta_files, num_workers=8)
peptide_seqs = parse_fasta_sequences("/content/drive/MyDrive/Deep Learning/peptideatlas.fasta")

#Runtime data loading positive pairs.

rpi2241_positive_pairs = load_rpi2241_pairs("/content/drive/MyDrive/Deep Learning/RPI2241.txt")

# This is an example of how to prepare model inputs, Applies the below function to RNA and peptide sequences.

rna_tensors = precompute_fasta_encodings(rna_seqs, one_hot_encodeRNA)
pep_tensors = precompute_fasta_encodings(peptide_seqs, one_hot_encodepeptide)

# Filepath for pickled cache storing parsed sequences from .pdb structures.

SEQUENCE_CACHE_PATH = "/content/drive/MyDrive/Deep Learning/structure_sequences_cache.pkl"
CACHE_VERSION = 1



rpi_structure_chains=get_cached_structure_sequences(pdb_dir="/content/drive/MyDrive/Deep Learning/pdb_files", cache_path=SEQUENCE_CACHE_PATH)

rpi2241_negative_pairs = generate_valid_negatives(positive_pairs=rpi2241_positive_pairs, structure_chains=rpi_structure_chains, num_negatives=len(rpi2241_positive_pairs))

all_labeled_pairs = positive_labeled + negative_labeled + fasta_negative_pairs


# step 13:Creates the full dataset, splits into train/val/test sets using stratified logic over .pdb IDs and FASTA pairs, then wraps with DataLoaders.


full_dataset = RNAPeptideDataset(labeled_pairs=all_labeled_pairs, structure_sequences=rpi_structure_chains, pdb_dir="/content/drive/MyDrive/Deep Learning/pdb_files", fasta_rna_seqs=rna_seqs, fasta_pep_seqs=peptide_seqs)

pdb_pairs = [pair for pair in all_labeled_pairs if len(pair[0].split("_")) == 2]
fasta_pairs = [pair for pair in all_labeled_pairs if len(pair[0].split("_")) != 2]

pdb_to_indices = defaultdict(list)
for idx, (prot_chain, rna_chain, label) in enumerate(pdb_pairs):
    pdb_id = prot_chain.split("_")[0].lower()
    pdb_to_indices[pdb_id].append(idx)

pdb_ids = list(pdb_to_indices.keys())
np.random.shuffle(pdb_ids)

n_total_pdb = len(pdb_ids)
n_train_pdb = int(0.8 * n_total_pdb)
n_val_pdb = int(0.15 * n_total_pdb)
n_test_pdb = n_total_pdb - n_train_pdb - n_val_pdb

train_pdbs = pdb_ids[:n_train_pdb]
val_pdbs = pdb_ids[n_train_pdb:n_train_pdb+n_val_pdb]
test_pdbs = pdb_ids[n_train_pdb+n_val_pdb:]

train_indices_pdb = [idx for pdb in train_pdbs for idx in pdb_to_indices[pdb]]
val_indices_pdb = [idx for pdb in val_pdbs for idx in pdb_to_indices[pdb]]
test_indices_pdb = [idx for pdb in test_pdbs for idx in pdb_to_indices[pdb]]

fasta_indices = list(range(len(pdb_pairs), len(pdb_pairs) + len(fasta_pairs)))
np.random.shuffle(fasta_indices)

n_total_fasta = len(fasta_indices)
n_train_fasta = int(0.8 * n_total_fasta)
n_val_fasta = int(0.15 * n_total_fasta)
n_test_fasta = n_total_fasta - n_train_fasta - n_val_fasta

train_indices_fasta = fasta_indices[:n_train_fasta]
val_indices_fasta = fasta_indices[n_train_fasta:n_train_fasta+n_val_fasta]
test_indices_fasta = fasta_indices[n_train_fasta+n_val_fasta:]

train_indices = train_indices_pdb + train_indices_fasta
val_indices = val_indices_pdb + val_indices_fasta
test_indices = test_indices_pdb + test_indices_fasta

train_dataset = Subset(full_dataset, train_indices)
val_dataset = Subset(full_dataset, val_indices)
test_dataset = Subset(full_dataset, test_indices)

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)


