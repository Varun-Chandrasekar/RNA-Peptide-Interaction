{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iTLU7OIo06Ne",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18650,
     "status": "ok",
     "timestamp": 1751847220760,
     "user": {
      "displayName": "Varun Chandrasekar",
      "userId": "05029472743074603588"
     },
     "user_tz": 420
    },
    "id": "iTLU7OIo06Ne",
    "outputId": "3d03059a-50cf-481a-e42f-42fdd0735a31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Biopython in /usr/local/lib/python3.11/dist-packages (1.85)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from Biopython) (2.0.2)\n"
     ]
    }
   ],
   "source": [
    "pip install Biopython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cT_WcFQ07Hl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 829,
     "status": "ok",
     "timestamp": 1751847222779,
     "user": {
      "displayName": "Varun Chandrasekar",
      "userId": "05029472743074603588"
     },
     "user_tz": 420
    },
    "id": "5cT_WcFQ07Hl",
    "outputId": "a10b339c-be6c-4c26-c17f-f4daf16be0fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a448e3",
   "metadata": {
    "id": "70a448e3"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, random_split, Dataset, Subset\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from itertools import islice\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from Bio import SeqIO\n",
    "from Bio.PDB import PDBList, PDBParser, PPBuilder\n",
    "from Bio.Seq import Seq\n",
    "from Bio.PDB.Polypeptide import is_aa\n",
    "from Bio.SeqUtils import seq1\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "import multiprocessing\n",
    "from Bio.PDB.Polypeptide import is_aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbac2213",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 448765,
     "status": "ok",
     "timestamp": 1751847822609,
     "user": {
      "displayName": "Varun Chandrasekar",
      "userId": "05029472743074603588"
     },
     "user_tz": 420
    },
    "id": "cbac2213",
    "outputId": "e140a118-bdb4-44ec-c5e3-3a436e4e1f06"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102321/102321 [06:58<00:00, 244.72it/s]\n"
     ]
    }
   ],
   "source": [
    "def parse_single_fasta_file(path):\n",
    "    with open(path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    sequence = ''.join([line.strip() for line in lines if not line.startswith(\">\")])\n",
    "    return sequence\n",
    "\n",
    "def parse_fasta_file(filepath):\n",
    "    try:\n",
    "        return [str(record.seq).strip().upper() for record in SeqIO.parse(filepath, \"fasta\")]\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "# Function to gather all .fasta/.fa files recursively\n",
    "def get_fasta_files_from_nested_folders(root_folder, limit=None):\n",
    "    files = glob.glob(os.path.join(root_folder, \"**\", \"*.fa*\"), recursive=True)\n",
    "    return list(islice(files, limit)) if limit else list(files)\n",
    "\n",
    "# Function to load sequences from multiple files using multiprocessing\n",
    "def load_fasta_sequences_parallel(file_list, num_workers=4):\n",
    "    if not file_list:\n",
    "        return []\n",
    "    with multiprocessing.Pool(processes=num_workers) as pool:\n",
    "        results = pool.imap_unordered(parse_fasta_file, file_list, chunksize=100)\n",
    "        sequences = []\n",
    "        for seq_list in tqdm(results, total=len(file_list)):\n",
    "            sequences.extend(seq_list)\n",
    "    return sequences\n",
    "\n",
    "def parse_fasta_sequences(filepath):\n",
    "    peptides = []\n",
    "    with open(filepath, 'r') as f:\n",
    "        current_seq = ''\n",
    "        for line in f:\n",
    "            if line.startswith('>'):\n",
    "                if current_seq:\n",
    "                    peptides.append(current_seq)\n",
    "                    current_seq = ''\n",
    "            else:\n",
    "                current_seq += line.strip()\n",
    "        if current_seq:\n",
    "            peptides.append(current_seq)\n",
    "    return peptides\n",
    "\n",
    "fasta_files = get_fasta_files_from_nested_folders(\"/content/drive/MyDrive/Deep Learning-RNA-Peptide-Interaction/RNA-fastaFiles\", limit=200000)\n",
    "rna_seqs = load_fasta_sequences_parallel(fasta_files, num_workers=8)\n",
    "peptide_seqs = parse_fasta_sequences(\"/content/drive/MyDrive/Deep Learning-RNA-Peptide-Interaction/peptideatlas.fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dfa7ef",
   "metadata": {
    "id": "f9dfa7ef"
   },
   "outputs": [],
   "source": [
    "def download_multiple_pdbs(pair_file, out_dir):\n",
    "    from Bio.PDB import PDBList\n",
    "    import os\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    pdbl = PDBList()\n",
    "    pdb_ids = set()\n",
    "\n",
    "    with open(pair_file, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) != 2 or parts[0].lower() == \"protein\":\n",
    "                continue  # Skip headers or malformed lines\n",
    "            prot, rna = parts\n",
    "            pdb_ids.add(prot.split(\"_\")[0].lower())\n",
    "\n",
    "    for pdb_id in sorted(pdb_ids):\n",
    "        try:\n",
    "            url = f\"https://files.rcsb.org/download/{pdb_id.upper()}.pdb\"\n",
    "            filepath = os.path.join(out_dir, f\"{pdb_id}.pdb\")\n",
    "            if not os.path.exists(filepath):\n",
    "                import urllib.request\n",
    "                urllib.request.urlretrieve(url, filepath)\n",
    "        except Exception:\n",
    "          print(f'Nothing')\n",
    "\n",
    "\n",
    "#download_multiple_pdbs(\"RPI2241.txt\", \"./pdb_files\")\n",
    "\n",
    "def load_rpi2241_pairs(filepath):\n",
    "    pairs = set()\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) != 2 or parts[0].lower() == \"protein\":\n",
    "                continue  # Skip headers or malformed lines\n",
    "            prot, rna = parts\n",
    "            pairs.add((prot.upper(), rna.upper()))\n",
    "    return pairs\n",
    "\n",
    "rpi2241_positive_pairs=load_rpi2241_pairs(\"/content/drive/MyDrive/Deep Learning-RNA-Peptide-Interaction/RPI2241.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8f28a1",
   "metadata": {
    "id": "0d8f28a1"
   },
   "outputs": [],
   "source": [
    "# One-hot encoding function for RNA and Peptide sequences\n",
    "def one_hot_encodeRNA(sequence):\n",
    "    mapping = {'A': 0, 'U': 1, 'G': 2, 'C': 3}\n",
    "    one_hot = np.zeros((len(sequence), 4))\n",
    "    for i, base in enumerate(sequence):\n",
    "        if base in mapping:\n",
    "            one_hot[i, mapping[base]] = 1\n",
    "    return torch.tensor(one_hot, dtype=torch.float)\n",
    "def one_hot_encodepeptide(sequence):\n",
    "    amino_acids = ['A', 'R', 'N', 'D', 'C', 'E', 'Q', 'G', 'H', 'I',\n",
    "    'L', 'K', 'M', 'F', 'P', 'S', 'T', 'W', 'Y', 'V']\n",
    "    aa_to_index = {aa: idx for idx, aa in enumerate(amino_acids)}\n",
    "    one_hot = np.zeros((len(sequence), 20))\n",
    "    for i, aa in enumerate(sequence):\n",
    "        if aa in aa_to_index:\n",
    "            one_hot[i, aa_to_index[aa]] = 1\n",
    "    return torch.tensor(one_hot, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cda5fa6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 104272,
     "status": "ok",
     "timestamp": 1751848903034,
     "user": {
      "displayName": "Varun Chandrasekar",
      "userId": "05029472743074603588"
     },
     "user_tz": 420
    },
    "id": "8cda5fa6",
    "outputId": "213ba85c-a58e-4553-daee-5be4db674b7d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102989/102989 [00:14<00:00, 7032.56it/s]\n",
      "100%|██████████| 2492451/2492451 [01:29<00:00, 27811.49it/s]\n"
     ]
    }
   ],
   "source": [
    "def precompute_fasta_encodings(seqs, encode_fn):\n",
    "    return [encode_fn(seq) for seq in tqdm(seqs)]\n",
    "\n",
    "rna_tensors = precompute_fasta_encodings(rna_seqs, one_hot_encodeRNA)\n",
    "pep_tensors = precompute_fasta_encodings(peptide_seqs, one_hot_encodepeptide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121a0928",
   "metadata": {
    "id": "121a0928"
   },
   "outputs": [],
   "source": [
    "RNA_MAP = {\n",
    "    \"ADE\": \"A\", \"CYT\": \"C\", \"GUA\": \"G\", \"URI\": \"U\",\n",
    "    \"PSU\": \"U\", \"INO\": \"I\", \"GTP\": \"G\", \"OMC\": \"C\",\n",
    "    \"A\": \"A\", \"C\": \"C\", \"G\": \"G\", \"U\": \"U\"  # Handle both 1/3-letter\n",
    "}\n",
    "\n",
    "AMINO_ACID_MAP = {\n",
    "    'ALA': 'A', 'ARG': 'R', 'ASN': 'N', 'ASP': 'D', 'CYS': 'C',\n",
    "    'GLU': 'E', 'GLN': 'Q', 'GLY': 'G', 'HIS': 'H', 'ILE': 'I',\n",
    "    'LEU': 'L', 'LYS': 'K', 'MET': 'M', 'PHE': 'F', 'PRO': 'P',\n",
    "    'SER': 'S', 'THR': 'T', 'TRP': 'W', 'TYR': 'Y', 'VAL': 'V',\n",
    "    'ASX': 'B', 'GLX': 'Z', 'SEC': 'U', 'PYL': 'O'  # Unusual residues\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d93d65",
   "metadata": {
    "id": "d9d93d65"
   },
   "outputs": [],
   "source": [
    "def get_chain_sequence(chain):\n",
    "    \"\"\"Optimized residue processing\"\"\"\n",
    "    seq = []\n",
    "    for residue in chain:\n",
    "        if residue.id[0] != \" \":  # Skip heteroatoms\n",
    "            continue\n",
    "        resname = residue.resname.strip().upper()\n",
    "        # Use direct mapping instead of seq1()\n",
    "        if resname in AMINO_ACID_MAP:\n",
    "            seq.append(AMINO_ACID_MAP[resname])\n",
    "        elif resname in RNA_MAP:\n",
    "            seq.append(RNA_MAP[resname])\n",
    "\n",
    "    return \"\".join(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63aad3d",
   "metadata": {
    "id": "f63aad3d"
   },
   "outputs": [],
   "source": [
    "SEQUENCE_CACHE_PATH = \"/content/drive/MyDrive/Deep Learning-RNA-Peptide-Interaction/structure_sequences_cache.pkl\"\n",
    "CACHE_VERSION = 1\n",
    "\n",
    "def get_chain_type(chain):\n",
    "  residues = list(chain.get_residues())\n",
    "  if not residues:\n",
    "    return None\n",
    "  if is_aa(residues[0]):\n",
    "    return 'protein'\n",
    "  else:\n",
    "    return 'rna'\n",
    "\n",
    "def get_cached_structure_sequences(pdb_dir, cache_path):\n",
    "  if os.path.exists(cache_path):\n",
    "    try:\n",
    "      with open(cache_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        if data.get('version') == CACHE_VERSION:\n",
    "          return data['sequences']\n",
    "    except Exception:\n",
    "      pass  # Recompute on error\n",
    "\n",
    "  structure_sequences = {}\n",
    "  parser = PDBParser(QUIET=True)\n",
    "\n",
    "  for pdb_file in os.listdir(pdb_dir):\n",
    "    if not pdb_file.lower().endswith(\".pdb\"):\n",
    "      continue\n",
    "    pdb_id = os.path.splitext(pdb_file)[0].lower()\n",
    "    file_path = os.path.join(pdb_dir, pdb_file)\n",
    "    try:\n",
    "      structure = parser.get_structure(pdb_id, file_path)\n",
    "      model = next(structure.get_models())\n",
    "      chains = {}\n",
    "\n",
    "      for chain in model:\n",
    "        chain_type = get_chain_type(chain)\n",
    "        if not chain_type:\n",
    "          continue\n",
    "        seq = get_chain_sequence(chain)\n",
    "        chains[chain.id] = {'type': chain_type, 'sequence': seq}\n",
    "\n",
    "      structure_sequences[pdb_id] = chains\n",
    "\n",
    "    except Exception as e:\n",
    "      print(f\"Error processing {pdb_id}: {str(e)}\")\n",
    "      continue\n",
    "\n",
    "  with open(cache_path, 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'version': CACHE_VERSION,\n",
    "        'sequences': structure_sequences\n",
    "        }, f)\n",
    "  return structure_sequences\n",
    "\n",
    "rpi_structure_chains=get_cached_structure_sequences(pdb_dir=\"/content/drive/MyDrive/Deep Learning-RNA-Peptide-Interaction/pdb_files\", cache_path=SEQUENCE_CACHE_PATH)\n",
    "\n",
    "def generate_valid_negatives(positive_pairs, structure_chains, num_negatives):\n",
    "  negative_pairs = []\n",
    "  positive_set = set((p, r) for p, r in positive_pairs)\n",
    "  all_pdbs = list(structure_chains.keys())\n",
    "\n",
    "  for _ in range(num_negatives):\n",
    "     # Select a random PDB with protein chains\n",
    "    pdb_id = random.choice(all_pdbs)\n",
    "    chains = rpi_structure_chains[pdb_id]\n",
    "\n",
    "    protein_chains = [cid for cid, info in chains.items() if info['type'] == 'protein']\n",
    "    rna_chains = [cid for cid, info in chains.items() if info['type'] == 'rna']\n",
    "\n",
    "    if not protein_chains or not rna_chains:\n",
    "      continue\n",
    "\n",
    "    prot_chain_id = random.choice(protein_chains)\n",
    "    rna_chain_id = random.choice(rna_chains)\n",
    "    prot_chain =f\"{pdb_id}_{prot_chain_id}\"\n",
    "    rna_chain = f\"{pdb_id}_{rna_chain_id}\"\n",
    "\n",
    "    if (prot_chain, rna_chain) in positive_set:\n",
    "      continue\n",
    "    negative_pairs.append((prot_chain, rna_chain, 0))\n",
    "\n",
    "  return negative_pairs\n",
    "\n",
    "rpi2241_negative_pairs = generate_valid_negatives(positive_pairs=rpi2241_positive_pairs, structure_chains=rpi_structure_chains, num_negatives=len(rpi2241_positive_pairs))\n",
    "\n",
    "fasta_negative_pairs = []\n",
    "for _ in range(len(rpi2241_positive_pairs)):\n",
    "    rna_seq = random.choice(rna_seqs)\n",
    "    pep_seq = random.choice(peptide_seqs)\n",
    "    rna_idx = random.randint(0, len(rna_seqs)-1)\n",
    "    pep_idx = random.randint(0, len(peptide_seqs)-1)\n",
    "    fasta_negative_pairs.append((rna_idx, pep_idx))\n",
    "\n",
    "positive_labeled = [(p, r, 1.0) for p, r in rpi2241_positive_pairs]\n",
    "negative_labeled = rpi2241_negative_pairs\n",
    "\n",
    "all_labeled_pairs = positive_labeled + negative_labeled + fasta_negative_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5966e37f",
   "metadata": {
    "id": "5966e37f"
   },
   "outputs": [],
   "source": [
    "ENCODING_CACHE = {}\n",
    "\n",
    "def cached_one_hot_encode(sequence, encoder, encoder_name):\n",
    "    key = (encoder_name, sequence)\n",
    "    if key not in ENCODING_CACHE:\n",
    "        ENCODING_CACHE[key] = encoder(sequence).float()\n",
    "    return ENCODING_CACHE[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae9f56e",
   "metadata": {
    "id": "5ae9f56e"
   },
   "outputs": [],
   "source": [
    "class RNAPeptideDataset(Dataset):\n",
    "  def __init__(self, labeled_pairs, structure_sequences, pdb_dir, fasta_rna_seqs=None, fasta_pep_seqs=None):\n",
    "    self.pairs = labeled_pairs\n",
    "    self.structure_sequences = structure_sequences\n",
    "    self.data = []\n",
    "    self.pdb_dir = pdb_dir\n",
    "    self.structure_cache = {}\n",
    "    self.sequence_cache = {}\n",
    "    self.fasta_rna_seqs = fasta_rna_seqs if fasta_rna_seqs is not None else []\n",
    "    self.fasta_pep_seqs = fasta_pep_seqs if fasta_pep_seqs is not None else []\n",
    "\n",
    "    for item in labeled_pairs:\n",
    "      if len(item) == 3:\n",
    "        if all(isinstance(x, str) for x in item[:2]):\n",
    "          prot_chain, rna_chain, label = item\n",
    "          self._process_pdb_pair(prot_chain, rna_chain, label)  # Fixed method name\n",
    "        elif len(item) == 2:\n",
    "          rna_idx, pep_idx = item#\n",
    "          self._process_fasta_pair(rna_idx, pep_idx)\n",
    "  def _process_pdb_pair(self, prot_chain, rna_chain, label):\n",
    "    if \"_\" not in prot_chain or \"_\" not in rna_chain:\n",
    "      return None\n",
    "    try:\n",
    "      pdb_id = prot_chain.split(\"_\")[0].lower()\n",
    "      pep_chain_id = prot_chain.split(\"_\")[1].upper()\n",
    "\n",
    "      rna_parts = rna_chain.split(\"_\")\n",
    "      rna_chain_id = rna_parts[1].upper() if len(rna_parts) > 1 else \"\"\n",
    "      # Get sequences from precomputed dict\n",
    "      chains = self.structure_sequences.get(pdb_id, {})\n",
    "      pep_seq = chains.get(pep_chain_id, \"\")\n",
    "      rna_seq = chains.get(rna_chain_id, \"\")\n",
    "\n",
    "      if not pep_seq or not rna_seq:\n",
    "        return None\n",
    "\n",
    "      self._add_to_data(rna_seq, pep_seq, label)\n",
    "\n",
    "    except IndexError as e:\n",
    "      print(f\"Format error in chain IDs: {e}\")\n",
    "      print(f\"prot_chain: {prot_chain}, rna_chain: {rna_chain}\")\n",
    "\n",
    "  def _process_fasta_pair(self, rna_idx, pep_idx):\n",
    "    try:\n",
    "      rna_seq = self.fasta_rna_seqs[rna_idx]\n",
    "      pep_seq = self.fasta_pep_seqs[pep_idx]\n",
    "      self._add_to_data(rna_seq, pep_seq, 0)\n",
    "    except IndexError:\n",
    "      return None\n",
    "\n",
    "  def _add_to_data(self, rna_seq, pep_seq, label):\n",
    "    rna_tensor = self._cached_encode(rna_seq['sequence'], \"RNA\")\n",
    "    pep_tensor = self._cached_encode(pep_seq['sequence'], \"PEP\")\n",
    "    label_tensor = torch.tensor([label], dtype=torch.float)\n",
    "\n",
    "    self.data.append((rna_tensor, pep_tensor, label_tensor))\n",
    "\n",
    "  def _cached_encode(self, sequence, seq_type):\n",
    "    cache_key = (sequence, seq_type)\n",
    "    if cache_key not in self.sequence_cache:\n",
    "      if seq_type == \"RNA\":\n",
    "        tensor = one_hot_encodeRNA(sequence).float()\n",
    "      else:\n",
    "        tensor = one_hot_encodepeptide(sequence).float()\n",
    "      self.sequence_cache[cache_key] = tensor\n",
    "    return self.sequence_cache[cache_key]\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    try:\n",
    "      return self.data[idx]\n",
    "    except IndexError:\n",
    "      return None\n",
    "\n",
    "def collate_fn(batch):\n",
    "  # Filter None items and check for empty batch\n",
    "  batch = [item for item in batch if item is not None]\n",
    "  if not batch:\n",
    "    return torch.tensor([]), torch.tensor([]), torch.tensor([])\n",
    "\n",
    "  # Unpack with shape validation\n",
    "  rna_seqs, pep_seqs, labels = [], [], []\n",
    "  for item in batch:\n",
    "    r, p, l = item\n",
    "    # Validate channel dimensions\n",
    "    if r.shape[-1] != 4:\n",
    "      r = F.one_hot(r.argmax(-1), num_classes=4).float()  # Repair RNA\n",
    "    if p.shape[-1] != 20:\n",
    "      p = F.one_hot(p.argmax(-1), num_classes=20).float() # Repair PEP\n",
    "    rna_seqs.append(r)\n",
    "    pep_seqs.append(p)\n",
    "    labels.append(l)\n",
    "\n",
    "  # Pad sequences\n",
    "  rna_padded = pad_sequence(rna_seqs, batch_first=True)\n",
    "  pep_padded = pad_sequence(pep_seqs, batch_first=True)\n",
    "\n",
    "  # Verify batch consistency\n",
    "  assert len(rna_padded) == len(pep_padded) == len(labels)\n",
    "  return rna_padded, pep_padded, torch.stack(labels)\n",
    "\n",
    "\n",
    "full_dataset = RNAPeptideDataset(labeled_pairs=all_labeled_pairs, structure_sequences=rpi_structure_chains, pdb_dir=\"/content/drive/MyDrive/Deep Learning-RNA-Peptide-Interaction/pdb_files\", fasta_rna_seqs=rna_seqs, fasta_pep_seqs=peptide_seqs)\n",
    "\n",
    "pdb_pairs = [pair for pair in all_labeled_pairs if isinstance(pair[0], str) and len(pair[0].split(\"_\")) == 2]\n",
    "fasta_pairs = [pair for pair in all_labeled_pairs if isinstance(pair[0], int) and isinstance(pair[1], int)]\n",
    "\n",
    "pdb_to_indices = defaultdict(list)\n",
    "for idx, (prot_chain, rna_chain, label) in enumerate(pdb_pairs):\n",
    "    pdb_id = prot_chain.split(\"_\")[0].lower()\n",
    "    pdb_to_indices[pdb_id].append(idx)\n",
    "\n",
    "pdb_ids = list(pdb_to_indices.keys())\n",
    "np.random.shuffle(pdb_ids)\n",
    "\n",
    "n_total_pdb = len(pdb_ids)\n",
    "n_train_pdb = int(0.8 * n_total_pdb)\n",
    "n_val_pdb = int(0.15 * n_total_pdb)\n",
    "n_test_pdb = n_total_pdb - n_train_pdb - n_val_pdb\n",
    "\n",
    "train_pdbs = pdb_ids[:n_train_pdb]\n",
    "val_pdbs = pdb_ids[n_train_pdb:n_train_pdb+n_val_pdb]\n",
    "test_pdbs = pdb_ids[n_train_pdb+n_val_pdb:]\n",
    "\n",
    "train_indices_pdb = [idx for pdb in train_pdbs for idx in pdb_to_indices[pdb]]\n",
    "val_indices_pdb = [idx for pdb in val_pdbs for idx in pdb_to_indices[pdb]]\n",
    "test_indices_pdb = [idx for pdb in test_pdbs for idx in pdb_to_indices[pdb]]\n",
    "\n",
    "fasta_indices = list(range(len(pdb_pairs), len(pdb_pairs) + len(fasta_pairs)))\n",
    "np.random.shuffle(fasta_indices)\n",
    "\n",
    "n_total_fasta = len(fasta_indices)\n",
    "n_train_fasta = int(0.8 * n_total_fasta)\n",
    "n_val_fasta = int(0.15 * n_total_fasta)\n",
    "n_test_fasta = n_total_fasta - n_train_fasta - n_val_fasta\n",
    "\n",
    "train_indices_fasta = fasta_indices[:n_train_fasta]\n",
    "val_indices_fasta = fasta_indices[n_train_fasta:n_train_fasta+n_val_fasta]\n",
    "test_indices_fasta = fasta_indices[n_train_fasta+n_val_fasta:]\n",
    "\n",
    "train_indices = train_indices_pdb + train_indices_fasta\n",
    "val_indices = val_indices_pdb + val_indices_fasta\n",
    "test_indices = test_indices_pdb + test_indices_fasta\n",
    "\n",
    "train_dataset = Subset(full_dataset, train_indices)\n",
    "val_dataset = Subset(full_dataset, val_indices)\n",
    "test_dataset = Subset(full_dataset, test_indices)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3c22fa",
   "metadata": {
    "id": "6f3c22fa"
   },
   "outputs": [],
   "source": [
    "# Define CNN model\n",
    "class CNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(CNN, self).__init__()\n",
    "    super(CNN, self).__init__()\n",
    "    self.rna_conv1 = nn.Conv1d(4, 16, kernel_size=3, padding=1)\n",
    "    self.rna_conv2 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
    "    self.rna_conv3 = nn.Conv1d(32, 64, kernel_size=3, padding=1)\n",
    "    self.rna_pool = nn.AdaptiveAvgPool1d(1)\n",
    "    self.pep_conv1 = nn.Conv1d(20, 16, kernel_size=3, padding=1)\n",
    "    self.pep_conv2 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
    "    self.pep_conv3 = nn.Conv1d(32, 64, kernel_size=3, padding=1)\n",
    "    self.pep_pool = nn.AdaptiveAvgPool1d(1)\n",
    "    self.fc1 = nn.Linear(128, 64)\n",
    "    self.fc2 = nn.Linear(64, 1)\n",
    "\n",
    "  def forward(self, rna_input, pep_input):\n",
    "    if rna_input.dim() == 1:\n",
    "      rna_input = F.one_hot(rna_input.long(), num_classes=4).float()\n",
    "    if pep_input.dim() == 1:\n",
    "      pep_input = F.one_hot(pep_input.long(), num_classes=20).float()\n",
    "\n",
    "    if rna_input.dim() == 2:\n",
    "      rna_input = rna_input.unsqueeze(0)\n",
    "    if pep_input.dim() == 2:\n",
    "      pep_input = pep_input.unsqueeze(0)\n",
    "\n",
    "    # Permute to [batch, channels, seq_len]\n",
    "    rna = rna_input.permute(0, 2, 1)\n",
    "    pep = pep_input.permute(0, 2, 1)\n",
    "\n",
    "    if rna.size(2) < 3:\n",
    "        rna = F.pad(rna, (0, 3 - rna.size(2)))\n",
    "    if pep.size(2) < 3:\n",
    "        pep = F.pad(pep, (0, 3 - pep.size(2)))\n",
    "\n",
    "    rna = F.relu(self.rna_conv1(rna))\n",
    "    rna = F.relu(self.rna_conv2(rna))\n",
    "    rna = F.relu(self.rna_conv3(rna))\n",
    "    rna = self.rna_pool(rna).squeeze(2)\n",
    "\n",
    "    pep = F.relu(self.pep_conv1(pep))\n",
    "    pep = F.relu(self.pep_conv2(pep))\n",
    "    pep = F.relu(self.pep_conv3(pep))\n",
    "    pep = self.pep_pool(pep).squeeze(2)\n",
    "\n",
    "    combined = torch.cat((rna, pep), dim=1)\n",
    "    x = F.relu(self.fc1(combined))\n",
    "    out = self.fc2(x)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be6349e",
   "metadata": {
    "id": "9be6349e"
   },
   "outputs": [],
   "source": [
    "# Initialize model, loss, optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN()\n",
    "total_positives=len(positive_labeled)\n",
    "total_negatives=len(fasta_negative_pairs) +len(negative_labeled)\n",
    "pos_weight_value = torch.tensor([total_negatives / total_positives])\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight_value)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2066a85",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 828983,
     "status": "ok",
     "timestamp": 1751853345479,
     "user": {
      "displayName": "Varun Chandrasekar",
      "userId": "05029472743074603588"
     },
     "user_tz": 420
    },
    "id": "a2066a85",
    "outputId": "db9a8156-53ec-4116-f4c5-94648b30b9f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/30], Loss: 0.8605\n",
      "Epoch [10/30], Val Loss: 0.8693\n",
      "Epoch [20/30], Loss: 0.8355\n",
      "Epoch [20/30], Val Loss: 0.8886\n",
      "Epoch [30/30], Loss: 0.8243\n",
      "Epoch [30/30], Val Loss: 0.8835\n"
     ]
    }
   ],
   "source": [
    "# Move model to device (GPU if available)\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "for epoch in range(30):\n",
    "  model.train()\n",
    "  train_losses = []\n",
    "\n",
    "  for batch in train_loader:\n",
    "    if batch is None:\n",
    "      continue\n",
    "\n",
    "    rna_batch, pep_batch, label_batch = batch\n",
    "    rna_batch = rna_batch.to(device)\n",
    "    pep_batch = pep_batch.to(device)\n",
    "    label_batch = label_batch.float().view(-1,1).to(device)\n",
    "\n",
    "    scores = model(rna_batch, pep_batch)\n",
    "    loss = criterion(scores, label_batch)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    train_losses.append(loss.item())\n",
    "\n",
    "  if len(train_losses) > 0:\n",
    "    avg_loss = sum(train_losses) / len(train_losses)\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "      print(f\"Epoch [{epoch + 1}/30], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "  # Validation\n",
    "  model.eval()\n",
    "  val_losses = []\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "      if batch is None:\n",
    "        continue\n",
    "\n",
    "      rna_batch, pep_batch, label_batch = batch\n",
    "\n",
    "      if rna_batch.size(0) == 0 or pep_batch.size(0) == 0 or label_batch.size(0) == 0:\n",
    "        continue\n",
    "\n",
    "      rna_batch = rna_batch.to(device)\n",
    "      pep_batch = pep_batch.to(device)\n",
    "      label_batch = label_batch.float().view(-1,1).to(device)\n",
    "\n",
    "      val_scores = model(rna_batch, pep_batch)\n",
    "      val_loss = criterion(val_scores, label_batch)\n",
    "      val_losses.append(val_loss.item())\n",
    "    if len(val_losses) > 0:\n",
    "      avg_val_loss = sum(val_losses) / len(val_losses)\n",
    "      if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch + 1}/30], Val Loss: {avg_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2256f73d",
   "metadata": {
    "id": "2256f73d"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"/content/drive/MyDrive/Deep Learning-RNA-Peptide-Interaction/models/cnn.pt\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
